{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "# Deep learning methods\n",
    "\n",
    "In this section, we will introduce three types of discriminative models on EEG data.    \n",
    "\n",
    "As shown in the first branch of the figure below, **discriminative models** mainly include Multi-Layer Perceptron (MLP), Recurrent Neural Networks(RNN), and Convolutional Neural Networks (CNN). The two mainstreams of RNN are Long Short-Term Memory (LSTM) and Gated Recurrent Unit (GRU).[<sup>1</sup>](#refer-anchor-1)\n",
    "\n",
    "![dlm](https://github.com/xiangzhang1015/Deep-Learning-for-BCI/blob/master/tutorial/dlm.PNG?raw=true)\n",
    "\n",
    "Apart from these, we will also present classification based on emerging graphical features (GNN classifier).\n",
    "\n",
    "<br>\n",
    "\n",
    "_In this tutorial, we provide all the codes in pytorch, make sure you have the __PyTorch__ machine learning framework installed. however, if you prefer to use __TensorFlow__, please check the projects(Repositories) in our github repositories. Projects relate to ML model on EEG:_\n",
    "- [MindID: EEG-based user identification](https://github.com/xiangzhang1015/MindID) ([paper](https://doi.org/10.1145/3264959), Chapter 9)\n",
    "- [Brain typing: convert EEG to text](https://github.com/xiangzhang1015/Brain_typing) ([paper](https://doi.org/10.1109/PERCOM.2018.8444575), Chapter 11)\n",
    "- [Adaptive feature learning](https://github.com/xiangzhang1015/know_your_mind) ([paper](https://doi.org/10.1109/ICDM.2019.00100), Chapter 7)\n",
    "- [Reconstruction of image based on visual evoked EEG](https://github.com/xiangzhang1015/EEG\\_Shape\\_Reconstruction) ([paper](http://ajiips.com.au/papers/V15.2/v15n2_40-47.pdf), Chapter 10)\n",
    "- [Neurological disorder (seizure) diagnosis](https://github.com/xiangzhang1015/adversarial\\_seizure\\_detection) ([paper](https://doi.org/10.1109/JBHI.2020.2971610), Chapter 13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Classification\" data-toc-modified-id=\"Classification-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Classification</a></span><ul class=\"toc-item\"><li><span><a href=\"#Classification-based-on-temporal-feature\" data-toc-modified-id=\"Classification-based-on-temporal-feature-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Classification based on temporal feature</a></span><ul class=\"toc-item\"><li><span><a href=\"#LSTM\" data-toc-modified-id=\"LSTM-1.1.1\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>LSTM</a></span></li><li><span><a href=\"#GRU\" data-toc-modified-id=\"GRU-1.1.2\"><span class=\"toc-item-num\">1.1.2&nbsp;&nbsp;</span>GRU</a></span></li></ul></li><li><span><a href=\"#Classification-based-on-spatial-feature\" data-toc-modified-id=\"Classification-based-on-spatial-feature-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Classification based on spatial feature</a></span></li><li><span><a href=\"#Classification-based-on-graphical-feature\" data-toc-modified-id=\"Classification-based-on-graphical-feature-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Classification based on graphical feature</a></span></li></ul></li><li><span><a href=\"#Reference\" data-toc-modified-id=\"Reference-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Reference</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification based on temporal feature\n",
    "In this part, we provide the code of two typical RNN architectures that can be used in EEG recognition.\n",
    "<!-- implementing on EEG data.     -->\n",
    "LSTM and GRU both follow the basic principles of RNN which is a specific subclass of discriminative deep learning model that are designed to capture temporal dependencies among input data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM\n",
    "[Long short-term memory](https://en.wikipedia.org/wiki/Long_short-term_memory) (LSTM) is the most popular RNN architecture which achived great success in diverse research topics such as handwriting recognition, speech recognition, and anomaly detection in network traffic. A common LSTM unit (a.k.a., cell) is composed of an input gate, an output gate and a forget gate; the cell remembers values over arbitrary time intervals and the three gates regulate the flow of information into and out of the cell. We recommend [this blog](http://colah.github.io/posts/2015-08-Understanding-LSTMs/) if you want to know eactly how data flow in LSTM cells. \n",
    "\n",
    "In this section, we use LSTM to capture the time-series information hidden in EEG signals. Please find our code at [4-1-1 Classification based on temporal feature(LSTM)](https://github.com/xiangzhang1015/Deep-Learning-for-BCI/blob/master/tutorial/4-1-1%20Classification%20based%20on%20temporal%20feature(LSTM).ipynb) (notebook) and [LSTM python script](https://github.com/xiangzhang1015/Deep-Learning-for-BCI/blob/master/pythonscripts/4-1-1_LSTM.py) (python file)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gated Recurrent Unit (GRU) is a variant or light version of LSTM. Compared to LSTM, GRU has less complex inside computations (less model parameters), which makes it less computational expensive and few training time. Mostly, GRU can achive comparable performance with LSTM and is more powerful to discover the latent distinct information from small-scale training dataset.\n",
    "\n",
    "Please find our GRU code on EEG classification at [4-1-2 Classification based on temporal feature(GRU)](https://github.com/xiangzhang1015/Deep-Learning-for-BCI/blob/master/tutorial/4-1-2%20Classification%20based%20on%20temporal%20feature(GRU).ipynb) (notebook) and [GRU python script](https://github.com/xiangzhang1015/Deep-Learning-for-BCI/blob/master/pythonscripts/4-1-2_GRU.py) (python file).\n",
    "\n",
    "By comparing the experimental results between LSTM (acc: 96.9%, running time: 200s) and GRU (acc: 95.4%, running time: 78s), we can find that the performence of these two RNN siblings are similar but GRU use only half of the training time compared to LSTM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification based on spatial feature\n",
    "Among all the deep learning models, CNN and its variants dominate the research of brain signal analysis by taking 37% proportion (Chapter 4.7 in our book). Like any deep learning models, CNN contains an input layer, hidden layers, and an output layer. However, the hidden layer could be very different and complex. For example, the number of hidden layers may vary from several layers to hundreds of layers. In a high level, a typical convolutional operation contains three components: convolution, pooling, and activation. This is a great [tutorial](https://cs231n.github.io/convolutional-networks/#overview) to understand the inside mechanism of CNN architecture. However, CNN contains a large number of hyper-parameters (such as filter size and strides in convolutional and pooling layers) need to be set by the user and the tuning is pretty tricky. Next, we provide a template for CNN-based EEG classification. Please find the scripts at [4-2 Classification based on spatial feature(CNN)](https://github.com/xiangzhang1015/Deep-Learning-for-BCI/blob/master/tutorial/4-2%20Classification%20based%20on%20spatial%20feature%20(CNN).ipynb) (notebook) and [CNN python script](https://github.com/xiangzhang1015/Deep-Learning-for-BCI/blob/master/pythonscripts/4-2_CNN.py) (python file). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification based on graphical feature\n",
    "Graph Neural Networks (GNN) are becoming very hot since 2018. The GNN can be divided into two categories based on the target graph. The main kind of GNNs (such as GCN, GAT, GraphSAGE, GHT) aiming at capturing interested information from *a single graph* with massive nodes and edges. The assumption is that all the nodes share similar distribution where each node/edge is regarded as a sample. We cannot use this kind of models for brain signal analysis. We can count on another category which focus on feature extration in *a batch of separate small graphs* where each small graph is regarded as a sample. The main idea to use GNN model to analyze brain signals is that formulating brain signals/images into a graph (composed of nodes and edges) and then discover the topological dependencies. \n",
    "\n",
    "Next, we provide a template for GNN-based EEG classification (we take GIN as an example). Please find the scripts at [4-3 Classification based on graphical feature (GIN)](https://github.com/xiangzhang1015/Deep-Learning-for-BCI/blob/master/tutorial/4-3%20Classification%20based%20on%20graphical%20feature%20(GIN).ipynb) (notebook) and [GIN python script](https://github.com/xiangzhang1015/Deep-Learning-for-BCI/blob/master/pythonscripts/4-3_GIN.py) (python file). Note, this script requires the installation of Pytorch Geometric package which is a geometric deep learning extension library for PyTorch. Please find the detailed [installation steps](https://pytorch-geometric.readthedocs.io/en/latest/notes/installation.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "\n",
    "<div id=\"refer-anchor-1\"></div>\n",
    "\n",
    "- [1]  [Zhang, X., Yao, L., Wang, X., Monaghan, J.J., Mcalpine, D. and Zhang, Y., 2020. A survey on deep learning-based non-invasive brain signals: recent advances and new frontiers. Journal of Neural Engineering.](https://iopscience.iop.org/article/10.1088/1741-2552/abc902/meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
