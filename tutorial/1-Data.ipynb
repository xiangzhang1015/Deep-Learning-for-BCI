{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><font size=10>Data organization</font><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction</a></span><ul class=\"toc-item\"><li><span><a href=\"#Dataset-description\" data-toc-modified-id=\"Dataset-description-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Dataset description</a></span></li><li><span><a href=\"#Load-dataset\" data-toc-modified-id=\"Load-dataset-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Load dataset</a></span></li></ul></li><li><span><a href=\"#Resampling\" data-toc-modified-id=\"Resampling-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Resampling</a></span><ul class=\"toc-item\"><li><span><a href=\"#Resampling-regarding-sampling-rate\" data-toc-modified-id=\"Resampling-regarding-sampling-rate-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Resampling regarding sampling rate</a></span></li><li><span><a href=\"#Resampling-regarding-data-size\" data-toc-modified-id=\"Resampling-regarding-data-size-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Resampling regarding data size</a></span></li></ul></li><li><span><a href=\"#Filtering\" data-toc-modified-id=\"Filtering-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Filtering</a></span></li><li><span><a href=\"#Reference\" data-toc-modified-id=\"Reference-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Reference</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we use the data from EEG Motor Movement/Imagery Dataset (EEG-MMIDB)[<sup>1</sup>](#refer-anchor-1). We offer the cleaned dataset that extract from the EEG-MMIDB that contains 109 subjects. In this tutorial, for simplicity, we take the first subject as a subset to show how the code works. The ready-to-use dataset can be find in the *dataset* folder.\n",
    "\n",
    "\n",
    "<!-- > Dataset_1: the data of the first subject in the EEG-MMIDB.  \n",
    "> Dataset_2: data of all 109 subjects of the EEG-MMIDB.\n",
    "\n",
    "* Note: in the following models of this BCI tutorial, we will use Dataset_1 to run examples for the computational advantage. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset description\n",
    "\n",
    "The original dataset description can be find here: https://archive.physionet.org/pn4/eegmmidb/\n",
    "\n",
    "After our clearning and sorting, each .npy file comprised of the data of one subject. The data shape of each npy file is [N, 65], the first 64 columns represent the readouts of 64 EEG channel, the last column denotes the class/intent label. The row denotes time-points in signal collection and one row represents one readout at a specific time-point. In this tutorial, we call each row a instance. The sampling rate in EEG-MMIDB is 160 Hz, which means that the equipment can generate 160 instances/rows/time-points in each second.\n",
    "\n",
    "\n",
    "The N varis for different subjects, but N should be 259,520 or 255,680. This is the inherent difference in the original dataset. Recall that the sampling rate is 160 Hz, thus, some trials last for 4.1 seconds while others last for 4.2 seconds: 4.1 seconds (656=4.1 $\\times$ 160 instances) or 4.2 seconds (672 = 4.2 $\\times$  160 instancs). It is suggested to segment the signals in each second. \n",
    "\n",
    "\n",
    "Based on the experimental setting, we split all EEG signals into 11 different cognitive intentions as follows. In which, the intentions with *image* represents the subject only image the action but not move in reality: these four intentions (labelled by 4, 5, 8, and 9) are strictly *movement imagery EEG*. The residual intentions are rather the mental states that the user was conducting a specific action.\n",
    "> Labels:  \n",
    "0: open eyes,  \n",
    "1: close eyes.  \n",
    "2: left hand,   \n",
    "3: right hand.  \n",
    "4: image left hand,   \n",
    "5: image right hand.  \n",
    "6: open fists,   \n",
    "7:open feet.  \n",
    "8: image fist,   \n",
    "9: image feet.  \n",
    "10: rest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset\n",
    "\n",
    "Next, we show how to load the data in 2 commands!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of Dataset_1: (259520, 65)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-16, -29,   2, ..., -11,  15,   0],\n",
       "       [-56, -54, -27, ...,   1,  21,   0],\n",
       "       [-55, -55, -29, ...,  18,  35,   0],\n",
       "       ...,\n",
       "       [  0,   0,   0, ...,   0,   0,   9],\n",
       "       [  0,   0,   0, ...,   0,   0,   9],\n",
       "       [  0,   0,   0, ...,   0,   0,   9]], dtype=int64)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "dataset_1=np.load('1.npy')\n",
    "print('The shape of Dataset_1:', dataset_1.shape)\n",
    "dataset_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from above, the data of subject 1 consists of 259520 instances and 64 channels while the last column denotes the class label (ground truth).\n",
    "\n",
    "We first introduce several terms about the data orgnization:\n",
    "* Instance (time step or time point). Each instance indicates a list of values which are collected at a single time point or sampling point. For example, there will be 160 instances in 1 second for the equipment with 160 Hz sampling rate. We use instance and time point interchangeably.\n",
    "\n",
    "* Segment (sample). Each segment contains multiple continue instances which can represent a specific event/state of brain signals. The length of a segment is called time window. We use segment and sample interchangeably.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resampling\n",
    "\n",
    "Sometimes we need to adjust the signal frequencies or proportion of samples before conducting any analysis. \n",
    "Resampling is a method that consists of drawing repeated samples from the original data samples[<sup>2</sup>](#refer-anchor-2). There are two types of resampling widely used:\n",
    "* Downsampling\n",
    "* Upsampling\n",
    "\n",
    "Next, we introduce the implementation of resampling in different conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling regarding sampling rate\n",
    "\n",
    "Regarding sampling rate/frequency of the input signal, we generally need to resample the input data in two scenarios. \n",
    "\n",
    "* The first one is to deal with multimodal signals. For example, we want to take advantage of two different input signals: brain signals (EEG) with 1000 Hz sampling rate and heart beat (ECG) with sampling rate of 20 Hz. In order to unify the input data and integrate them together, we need to adjust them into a constant samling rate, let's say 200 Hz. The practical operation is straightforwad that sample one instance from each of five continue instances in EEG (downsampling), while five is calculated by 1000/200; at the meantime, repeat each instance in ECG for 10 times (upsampling), while 10 is calculated by 200/20. \n",
    "\n",
    "\n",
    "* Resampling can also apply to the scenario that the input signals have very high sampling frequency which we don't need. Take the EEG data with 1000 sampling rate as an example: one background knowledge is that the most useful information in EEG are under 70 Hz, based on Nyquist Sampling Theorem, we only need signals with sampling rate around 140 Hz. To reduce computational cost, it's not compulsory but acceptable to downsample the original high-frequency signal (1000 Hz) to lower-frequency signals (e.g., 160 Hz). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling regarding data size\n",
    "\n",
    "This kind of resampling aims to keep balance between datasets (both training and testing set). For example, we have 1000 positive samples but only 200 negative samples, which is called *imbalance* in machine learning. The classifier can achieve an accuracy of 80% by just blindly predicted the most frequent class (i.e., make all predection as positive prediction). Addressing this issue, there are three typical solutions: \n",
    "1. Downsampling the most frequent class until a more balanced distribution is reached (e.g., randomly selecting examples from the majority class and deleting them from the training dataset). \n",
    "2. Upsampling the least frequent class (e.g., randomly duplicating examples from the minority class). \n",
    "3. Use other evaluation metrics, such as ROC Curves and AUROC (Area Under ROC) which could mitigate the imbalanced data issue. \n",
    "\n",
    "*In this tutorial,we do not need resampling since our data has appropriate sampling frequency and is already balanced.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering\n",
    "\n",
    "Sometimes we need to filter the EEG signals into frequency bands of interests, in order to find the most informative and distinguishable patterns. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The EEG signals collected from any typical EEG hardware have several nonoverlapping frequency bands (Delta, Theta, Alpha, Beta, and Gamma) based on the strong intraband correlation with a distinct behavioral state. Each EEG pattern contains signals associated with particular brain information. The degree of awareness denotes the perception of individuals when presented with external stimuli. It is mainly defined in physiology instead of psychology.[<sup>3</sup>](#refer-anchor-3)  \n",
    "\n",
    "Each frequency band represents a brain state and a qualitative assessment of awareness:\n",
    "* Delta pattern (0.5--4 Hz) corresponds to deep sleep when the subject has lower awareness.  \n",
    "- Theta pattern (4--8 Hz) corresponds to light sleep in the realm of low awareness.   \n",
    "* Alpha pattern (8--12 Hz) mainly occurs during eyes closed and deeply relaxed state and corresponds to the medium awareness. \n",
    "* Beta pattern (12--30 Hz) is the dominant rhythm while the eyes of the subject are open and is associated with high awareness. Beta patterns capture most of our daily activities (such as eating, walking, and talking). \n",
    "* Gamma pattern (30--100 Hz) represents the co-interaction of several brain areas to carry out a specific motor and cognitive function. \n",
    "\n",
    "Next, we provide the filtering codes taking the Delta band as an example (we don't need filtering in this tutorial, just provide the code in case the readers need it). The filter used here is 3-order band-pass butterworth filter. Please adjust sampling frequency (fs), lowcut and highcut to customize your own filter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from BCI_functions.ipynb\n",
      "The shape of filtered feature: (259520, 64)\n",
      "The shape of dataset_1 after filtering: (259520, 65)\n"
     ]
    }
   ],
   "source": [
    "import myimporter  # active import from inside notebook\n",
    "from BCI_functions import *  # BCI_functions.ipynb contains some functions we might use multiple times in this tutorial \n",
    "\n",
    "n_fea = 64  # 64 channels\n",
    "label = dataset_1[:, n_fea: n_fea+1]  # seperate label from feature\n",
    "feature = dataset_1[:, 0:n_fea] \n",
    "feature_f=[]  # feature after filtering\n",
    "\n",
    "# EEG Delta pattern decomposition\n",
    "for i in range(feature.shape[1]):\n",
    "    x = feature[:, i]\n",
    "    fs = 160.0\n",
    "    lowcut = 0.5\n",
    "    highcut = 4.0\n",
    "    y = butter_bandpass_filter(x, lowcut, highcut, fs, order=3)\n",
    "    feature_f.append(y) \n",
    "    \n",
    "feature_f=np.array(feature_f).T\n",
    "print('The shape of filtered feature:',feature_f.shape)\n",
    "\n",
    "data_f=np.hstack((feature_f,label))  # stack label to filtered feature \n",
    "print(\"The shape of dataset_1 after filtering:\",data_f.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "\n",
    "<div id=\"refer-anchor-1\"></div>\n",
    "\n",
    "- [1]  [Goldberger AL, Amaral LAN, Glass L, Hausdorff JM, Ivanov PCh, Mark RG, Mietus JE, Moody GB, Peng C-K, Stanley HE. PhysioBank, PhysioToolkit, and PhysioNet: Components of a New Research Resource for Complex Physiologic Signals. Circulation 101(23):e215-e220](http://circ.ahajournals.org/cgi/content/full/101/23/e215)\n",
    "\n",
    "<div id=\"refer-anchor-2\"></div>\n",
    "\n",
    "- [2]  [Resampling Imbalanced Data and Applying Machine Learning Techniques](https://medium.com/better-programming/resampling-imbalanced-data-and-applying-ml-techniques-91ebce40ff4d)\n",
    "\n",
    "<div id=\"refer-anchor-2\"></div>\n",
    "\n",
    "- [3]  [Zhang X, Yao L, Wang X, et al. A survey on deep learning-based non-invasive brain signals: recent advances and new frontiers[J]. Journal of Neural Engineering, 2020.](https://arxiv.org/abs/1905.04149)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
